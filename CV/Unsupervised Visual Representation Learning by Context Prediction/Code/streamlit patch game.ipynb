{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb9029c",
   "metadata": {},
   "source": [
    "# Where's Waldo - Patch Direction Game\n",
    "## Unified Streamlit + PyTorch Notebook\n",
    "This script creates an interactive web application using Streamlit for a \"Patch Direction Game\".\n",
    "\n",
    "It loads image pairs (a central patch and a neighboring patch) and displays them to the user. The user then guesses the direction of the neighboring patch relative to the central one using on-screen buttons. The script also loads a pre-trained Convolutional Neural Network (CNN) built with PyTorch which predicts the same direction based on the image patches. Finally, the application provides feedback on the user's guess, shows the AI model's prediction for comparison, and keeps score.\n",
    "\n",
    "Realized by Nikola Trouhtchev, Hugo M. V. Arsenio, Dan Anghel\n",
    "\n",
    "Requires: `torch`, `numpy`, `opencv-python` (for cv2), `torchvision`, and `streamlit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595fdf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List\n",
    "from torchvision import transforms\n",
    "import streamlit as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchPositionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PatchPositionNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(6, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((4, 4)),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 8)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4158a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PatchConfig:\n",
    "    patch_size: int = 32\n",
    "    gap: int = 16\n",
    "    jitter: int = 4\n",
    "    max_image_size: Tuple[int, int] = (128, 128)\n",
    "    color_drop: bool = True\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "def load_images_from_folder(folder: str, config: PatchConfig) -> List[Tuple[str, np.ndarray]]:\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, config.max_image_size)\n",
    "            images.append((filename, img))\n",
    "    return images\n",
    "\n",
    "def apply_color_dropping(patch: np.ndarray) -> np.ndarray:\n",
    "    keep_channel = np.random.randint(3)\n",
    "    noise = np.random.normal(0, 1, patch.shape).astype(np.uint8)\n",
    "    dropped = np.copy(patch)\n",
    "    for c in range(3):\n",
    "        if c != keep_channel:\n",
    "            dropped[:, :, c] = noise[:, :, c]\n",
    "    return dropped\n",
    "\n",
    "def extract_random_patch_pair(img: np.ndarray, config: PatchConfig, apply_color_drop: bool = True) -> Tuple[np.ndarray, np.ndarray, int]:\n",
    "    h, w, _ = img.shape\n",
    "    margin = config.patch_size + config.gap + config.jitter\n",
    "    DIRECTION_MAP = {\n",
    "        0: ( 0,  1), 1: (-1,  1), 2: (-1,  0), 3: (-1, -1),\n",
    "        4: ( 0, -1), 5: ( 1, -1), 6: ( 1,  0), 7: ( 1,  1)\n",
    "    }\n",
    "    shift = config.patch_size + config.gap\n",
    "    for _ in range(20):\n",
    "        if h <= 2 * margin or w <= 2 * margin:\n",
    "            raise ValueError(\"Image is too small to extract patches with the given config.\")\n",
    "        x1 = np.random.randint(margin, w - margin)\n",
    "        y1 = np.random.randint(margin, h - margin)\n",
    "        dx_jit, dy_jit = np.random.randint(-config.jitter, config.jitter + 1, size=2)\n",
    "        x1 += dx_jit\n",
    "        y1 += dy_jit\n",
    "        valid_directions = []\n",
    "        for label, (dy, dx) in DIRECTION_MAP.items():\n",
    "            x2 = x1 + dx * shift\n",
    "            y2 = y1 + dy * shift\n",
    "            if (0 <= x2 < w - config.patch_size and 0 <= y2 < h - config.patch_size):\n",
    "                valid_directions.append((label, x2, y2))\n",
    "        if not valid_directions:\n",
    "            continue\n",
    "        direction, x2, y2 = valid_directions[np.random.randint(len(valid_directions))]\n",
    "        patch1 = img[y1:y1 + config.patch_size, x1:x1 + config.patch_size]\n",
    "        patch2 = img[y2:y2 + config.patch_size, x2:x2 + config.patch_size]\n",
    "        if patch1.shape != (config.patch_size, config.patch_size, 3) or patch2.shape != (config.patch_size, config.patch_size, 3):\n",
    "            continue\n",
    "        if apply_color_drop and config.color_drop:\n",
    "            patch1 = apply_color_dropping(patch1)\n",
    "            patch2 = apply_color_dropping(patch2)\n",
    "        return patch1, patch2, direction\n",
    "    raise ValueError(\"Failed to extract a valid patch pair after 20 attempts.\")\n",
    "\n",
    "def preprocess_patch_pair(p1: np.ndarray, p2: np.ndarray) -> torch.Tensor:\n",
    "    t1 = transform(p1)\n",
    "    t2 = transform(p2)\n",
    "    return torch.cat([t1, t2], dim=0).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9057441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ee6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PatchConfig(patch_size=28, gap=8, jitter=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = PatchPositionNet().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "images = load_images_from_folder(\"images\", config)\n",
    "direction_names = [\"Right\", \"Top-Right\", \"Top\", \"Top-Left\", \"Left\", \"Bottom-Left\", \"Bottom\", \"Bottom-Right\"]\n",
    "\n",
    "st.title(\"Where's Waldo - Patch Direction Game\")\n",
    "idx = np.random.randint(len(images))\n",
    "filename, img = images[idx]\n",
    "st.write(f\"Image: {filename}\")\n",
    "\n",
    "try:\n",
    "    p1, p2, label = extract_random_patch_pair(img, config, apply_color_drop=False)\n",
    "except ValueError:\n",
    "    st.error(\"Image is too small for patch extraction.\")\n",
    "    st.stop()\n",
    "\n",
    "bordered_p1 = cv2.copyMakeBorder(p1, 2, 2, 2, 2, cv2.BORDER_CONSTANT, value=(255, 0, 0))\n",
    "bordered_p2 = cv2.copyMakeBorder(p2, 2, 2, 2, 2, cv2.BORDER_CONSTANT, value=(0, 0, 255))\n",
    "combined = np.hstack([bordered_p1, bordered_p2])\n",
    "st.image(combined, channels=\"BGR\", width=256)\n",
    "\n",
    "input_tensor = preprocess_patch_pair(p1, p2).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(input_tensor)\n",
    "    pred = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "st.subheader(\"Guess the direction of the red patch (from blue):\")\n",
    "col1, col2, col3 = st.columns(3)\n",
    "guessed = st.session_state.get(\"guessed\", False)\n",
    "\n",
    "def guess(direction_idx):\n",
    "    st.session_state.clicked = direction_idx\n",
    "    st.session_state.guessed = True\n",
    "\n",
    "with col1:\n",
    "    if st.button(\"Top-Left\"): guess(3)\n",
    "    if st.button(\"Left\"): guess(4)\n",
    "    if st.button(\"Bottom-Left\"): guess(5)\n",
    "\n",
    "with col2:\n",
    "    if st.button(\"Top\"): guess(2)\n",
    "    st.write(\" \")\n",
    "    if st.button(\"Bottom\"): guess(6)\n",
    "\n",
    "with col3:\n",
    "    if st.button(\"Top-Right\"): guess(1)\n",
    "    if st.button(\"Right\"): guess(0)\n",
    "    if st.button(\"Bottom-Right\"): guess(7)\n",
    "\n",
    "if st.session_state.get(\"guessed\", False):\n",
    "    user_dir = direction_names[st.session_state.clicked]\n",
    "    correct_dir = direction_names[label]\n",
    "    model_dir = direction_names[pred]\n",
    "    st.markdown(\"---\")\n",
    "    if st.session_state.clicked == label:\n",
    "        st.success(f\"‚úÖ Correct! You picked: **{user_dir}**\")\n",
    "    else:\n",
    "        st.error(f\"‚ùå Wrong. You picked: **{user_dir}** ‚Äî Correct: **{correct_dir}**\")\n",
    "    st.info(f\"ü§ñ Model predicted: **{model_dir}**\")\n",
    "    if st.button(\"Play Again\"):\n",
    "        st.session_state.guessed = False\n",
    "        st.rerun()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
